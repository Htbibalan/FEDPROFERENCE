{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b88d233a-7fa6-4412-be99-883a039eef89",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '\\\\workspaces\\\\FEDPROFERENCE\\\\FEDXD_METAFILE.xls'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 97\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;66;03m#%%\u001b[39;00m\n\u001b[0;32m     94\u001b[0m \n\u001b[0;32m     95\u001b[0m \u001b[38;5;66;03m# function to get timestamps from fed csv files\u001b[39;00m\n\u001b[0;32m     96\u001b[0m metafile \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/workspaces/FEDPROFERENCE/FEDXD_METAFILE.xls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 97\u001b[0m rows, header \u001b[38;5;241m=\u001b[39m tp\u001b[38;5;241m.\u001b[39mmetafilereader(metafile, sheetname\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMETAFILE\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     99\u001b[0m mice \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m rows:\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\DATA\\Lib\\site-packages\\trompy\\metafile_utils.py:50\u001b[0m, in \u001b[0;36mmetafilereader\u001b[1;34m(filename, sheetname, delimiter)\u001b[0m\n\u001b[0;32m     47\u001b[0m     wb\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m extension \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.xls\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 50\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m xlrd\u001b[38;5;241m.\u001b[39mopen_workbook(filename) \u001b[38;5;28;01mas\u001b[39;00m wb:\n\u001b[0;32m     51\u001b[0m         sh \u001b[38;5;241m=\u001b[39m wb\u001b[38;5;241m.\u001b[39msheet_by_name(sheetname)  \u001b[38;5;66;03m# or wb.sheet_by_name('name_of_the_sheet_here')\u001b[39;00m\n\u001b[0;32m     53\u001b[0m         header \u001b[38;5;241m=\u001b[39m sh\u001b[38;5;241m.\u001b[39mrow_values(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\DATA\\Lib\\site-packages\\xlrd\\__init__.py:166\u001b[0m, in \u001b[0;36mopen_workbook\u001b[1;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows, ignore_workbook_corruption)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen_workbook\u001b[39m(filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     85\u001b[0m                   logfile\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mstdout,\n\u001b[0;32m     86\u001b[0m                   verbosity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     93\u001b[0m                   ignore_workbook_corruption\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     94\u001b[0m                   ):\n\u001b[0;32m     95\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;124;03m    Open a spreadsheet file for data extraction.\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;124;03m    :returns: An instance of the :class:`~xlrd.book.Book` class.\u001b[39;00m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 166\u001b[0m     file_format \u001b[38;5;241m=\u001b[39m inspect_format(filename, file_contents)\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;66;03m# We have to let unknown file formats pass through here, as some ancient\u001b[39;00m\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;66;03m# files that xlrd can parse don't start with the expected signature.\u001b[39;00m\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m file_format \u001b[38;5;129;01mand\u001b[39;00m file_format \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\DATA\\Lib\\site-packages\\xlrd\\__init__.py:60\u001b[0m, in \u001b[0;36minspect_format\u001b[1;34m(path, content)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     59\u001b[0m     path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexpanduser(path)\n\u001b[1;32m---> 60\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     61\u001b[0m         peek \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread(PEEK_SIZE)\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m peek\u001b[38;5;241m.\u001b[39mstartswith(XLS_SIGNATURE):\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '\\\\workspaces\\\\FEDPROFERENCE\\\\FEDXD_METAFILE.xls'"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "# This is where I might put helper functions and scripts\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import trompy as tp\n",
    "\n",
    "def get_FEDevents(filename, eventname):\n",
    "    \n",
    "    formats = ['%Y-%m-%d %H:%M:%S', '%m/%d/%Y %H:%M:%S']\n",
    "\n",
    "    file = open (filename)\n",
    "    csvreader= csv.reader(file)\n",
    "    next(csvreader)\n",
    "    rows= []\n",
    "    for row in csvreader:\n",
    "        rows.append(row)\n",
    "\n",
    "    # works out which format should be used\n",
    "\n",
    "\n",
    "    \n",
    "    try:\n",
    "        tmp_date_time_obj = datetime.strptime(rows[0][0], formats[0])\n",
    "        date_format = formats[0]\n",
    "    except ValueError:\n",
    "        tmp_date_time_obj = datetime.strptime(rows[0][0], formats[1])\n",
    "        date_format = formats[1]\n",
    "\n",
    "    timestamps = []\n",
    "    for row in rows: \n",
    "        if row[9] == eventname:\n",
    "            date_time_obj = datetime.strptime(row [0], date_format)\n",
    "            timestamps.append (date_time_obj)\n",
    "           \n",
    "    t0 = rows[0] [0] \n",
    "    day = t0.split()[0] \n",
    "    lightson = day + \" 07:00:00\" \n",
    "    refpoint = datetime.strptime(lightson, date_format)\n",
    "    \n",
    "    pellettimes = []\n",
    "    for t in timestamps:\n",
    "        Deltat = t-refpoint\n",
    "        Deltatinseconds = Deltat.total_seconds()\n",
    "        Deltatinhours = Deltatinseconds/3600\n",
    "        pellettimes.append(Deltatinhours)\n",
    "\n",
    "    return pellettimes\n",
    "\n",
    "def get_data_subset(dictionary, selectors, verbose=True):\n",
    "\n",
    "    output_dictionary = dictionary.copy()\n",
    "    for key, value in selectors.items():\n",
    "        for mouse_id in dictionary.keys():\n",
    "            try:\n",
    "                if output_dictionary[mouse_id][key] != value:\n",
    "                    output_dictionary.pop(mouse_id)\n",
    "            except KeyError: pass\n",
    "\n",
    "    if verbose:\n",
    "        print(\"{} items in output dictionary\".format(len(output_dictionary.keys())))\n",
    "    \n",
    "    return output_dictionary\n",
    "\n",
    "def get_data_fields(dictionary, fields, selectors):\n",
    "\n",
    "    output_list = []\n",
    "    reduced_dictionary = get_data_subset(dictionary, selectors)\n",
    "    \n",
    "    if len(reduced_dictionary.keys()) > 0:\n",
    "\n",
    "        for field in fields:\n",
    "            output_sublist =[]\n",
    "            try:\n",
    "                for key in reduced_dictionary.keys():\n",
    "                    output_sublist.append(reduced_dictionary[key][field])\n",
    "            except KeyError:\n",
    "                print(\"{} is not a key in selected dictionary\".format(field))\n",
    "                return\n",
    "            output_list.append(output_sublist)\n",
    "    else:\n",
    "        print(\"No data in fields in selected dictionary\")\n",
    "\n",
    "    if len(output_list) == 1:\n",
    "        output_list = output_list[0]\n",
    "        \n",
    "    return output_list\n",
    "\n",
    "def get_intermealinterval (pellettimes):\n",
    "    IPIs = np.diff(pellettimes)\n",
    "    IMI= np.mean([x for x in IPIs if x > (1/60)])\n",
    "    return IMI\n",
    "#%%\n",
    "\n",
    "# function to get timestamps from fed csv files\n",
    "metafile = \"/workspaces/FEDPROFERENCE/FEDXD_METAFILE.xls\"\n",
    "rows, header = tp.metafilereader(metafile, sheetname=\"METAFILE\")\n",
    "\n",
    "mice = {}\n",
    "for row in rows:\n",
    "    mouse_id = row[0]\n",
    "    if mouse_id not in mice.keys():\n",
    "        mice[mouse_id] = {}\n",
    "        mice[mouse_id][\"SEX\"] = row[1]\n",
    "        mice[mouse_id][\"CHOICE_SESSION\"] = row[4]\n",
    "        mice[mouse_id][\"FED_PELLET\"] = row[5]\n",
    "        mice[mouse_id][\"MODE\"] = row[6]\n",
    "        mice[mouse_id][\"DIET\"] = row[7]\n",
    "\n",
    "for key in mice.keys():\n",
    "    for row in rows:\n",
    "        if row[0] == key and row[6] == \"FR\":\n",
    "            filename = \"/workspaces/FEDPROFERENCE/data/{}\".format(row[3])\n",
    "            if row[5] == \"CAS20\":\n",
    "                mice[key][\"CAS20_timestamps\"] = get_FEDevents(filename, \"Pellet\")\n",
    "            elif row[7] == \"PR\":\n",
    "                mice[key][\"pr_timestamps\"] = get_FEDevents(filename, \"Pellet\")\n",
    "            elif row[7] == \"NR\":\n",
    "                mice[key][\"nr_timestamps\"] = get_FEDevents(filename, \"Pellet\")\n",
    "            else:\n",
    "                print(row[27], \"is not a valid type of pellet for\", key)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# %%\n",
    "# to get average pellets per day\n",
    "for key in mice.keys():\n",
    "    mice[key][\"grain_avg_pellets\"] = len(mice[key][\"grain_timestamps\"]) / 3\n",
    "    mice[key][\"pr_avg_pellets\"] = len(mice[key][\"pr_timestamps\"]) / 7\n",
    "    mice[key][\"nr_avg_pellets\"] = len(mice[key][\"nr_timestamps\"]) / 7\n",
    "\n",
    "# %%\n",
    "# \n",
    "def get_pellets_per_day(timestamps, start_time=4, days=7):\n",
    "    pellets_per_day = []\n",
    "    for day in range(days):\n",
    "        pellets = [t for t in timestamps if (t>day*24) and (t<(day+1)*24)]\n",
    "        n_pellets = len(pellets)\n",
    "        pellets_per_day.append(n_pellets)\n",
    "\n",
    "    return pellets_per_day\n",
    "\n",
    "for key in mice.keys():\n",
    "    mice[key][\"grain_pellets_per_day\"] = get_pellets_per_day(mice[key][\"grain_timestamps\"], days=3)\n",
    "    mice[key][\"pr_pellets_per_day\"] = get_pellets_per_day(mice[key][\"pr_timestamps\"])\n",
    "    mice[key][\"nr_pellets_per_day\"] = get_pellets_per_day(mice[key][\"nr_timestamps\"])\n",
    "\n",
    "# %%\n",
    "# assemble pellets per day for whole timecourse\n",
    "for key in mice.keys():\n",
    "    if mice[key][\"order\"] == 2:\n",
    "        mice[key][\"all_pellets_per_day\"] = mice[key][\"grain_pellets_per_day\"] + \\\n",
    "            mice[key][\"pr_pellets_per_day\"] + mice[key][\"nr_pellets_per_day\"]\n",
    "    else:\n",
    "                mice[key][\"all_pellets_per_day\"] = mice[key][\"grain_pellets_per_day\"] + \\\n",
    "                    mice[key][\"nr_pellets_per_day\"] + mice[key][\"pr_pellets_per_day\"]\n",
    "\n",
    "\n",
    "\n",
    "# %%\n",
    "# add meal parameters to dictionary\n",
    "\n",
    "def get_interpellet_intervals(pellettimes):\n",
    "    IPIs = np.diff(pellettimes)\n",
    "    return IPIs\n",
    "\n",
    "def get_intermealinterval (pellettimes):\n",
    "    IPIs = np.diff(pellettimes)\n",
    "    IMI= np.mean([x for x in IPIs if x > (1/60)])\n",
    "    return IMI\n",
    "\n",
    "def get_mealsize(pellettimes):\n",
    "    \"\"\"\n",
    "    calculates meal size from times of pellets\n",
    "    parameters \n",
    "    ----------\n",
    "    pellettimes : list of floats\n",
    "        timestamps of pellet deliveries\n",
    "\n",
    "    returns\n",
    "    --------\n",
    "    mealsize : float \n",
    "        mean size of meal in pellets \n",
    "    \"\"\"\n",
    "    npellets = len(pellettimes)\n",
    "    IPIs = np.diff(pellettimes)\n",
    "    nmeals = len([idx for idx, val in enumerate(IPIs) if val > 1/60])\n",
    "    mealsize = npellets/nmeals\n",
    "\n",
    "    return mealsize\n",
    "\n",
    "for key in mice.keys():\n",
    "    pr_timestamps = mice[key][\"pr_timestamps\"]\n",
    "    mice[key][\"interpellet_intervals_pr\"] = get_interpellet_intervals(pr_timestamps)\n",
    "    mice[key][\"intermeal_interval_pr\"] = get_intermealinterval(pr_timestamps)\n",
    "    mice[key][\"mealsize_pr\"] = get_mealsize(pr_timestamps)\n",
    "\n",
    "    nr_timestamps = mice[key][\"nr_timestamps\"]\n",
    "    mice[key][\"interpellet_intervals_nr\"] = get_interpellet_intervals(nr_timestamps)\n",
    "    mice[key][\"intermeal_interval_nr\"] = get_intermealinterval(nr_timestamps)\n",
    "    mice[key][\"mealsize_nr\"] = get_mealsize(nr_timestamps)\n",
    "    \n",
    "# %%\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "153c386e-b07a-4de9-acff-a5e4e28bc7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_FEDevents(filename, eventname):\n",
    "    formats = ['%m/%d/%Y %H:%M:%S']  # Adjusted to the format in your CSV\n",
    "    file = open(filename)\n",
    "    csvreader = csv.reader(file)\n",
    "    next(csvreader)  # Skip header\n",
    "    rows = [row for row in csvreader]\n",
    "\n",
    "    if not rows:  # Check if rows is empty\n",
    "        print(f\"No data in file {filename}.\")\n",
    "        return []\n",
    "\n",
    "    # Assuming the first column contains the date and time info\n",
    "    # and the \"Event\" column is consistent with the provided files\n",
    "    event_column_index = 9  # Based on your CSV structure\n",
    "    \n",
    "    # Determine which date format should be used (assuming consistency, so just using one format)\n",
    "    date_format = formats[0]\n",
    "\n",
    "    timestamps = []\n",
    "    for row in rows:\n",
    "        if row[event_column_index] == eventname:\n",
    "            date_time_obj = datetime.strptime(row[0], date_format)\n",
    "            timestamps.append(date_time_obj)\n",
    "\n",
    "    if not timestamps:  # If no events match, return an empty list\n",
    "        return []\n",
    "\n",
    "    # Calculate time since \"lights on\", using the first event as reference if needed\n",
    "    t0 = timestamps[0].strftime(date_format)\n",
    "    day = t0.split()[0]\n",
    "    lightson = day + \" 07:00:00\"  # Assuming lights on at 7 AM\n",
    "    refpoint = datetime.strptime(lightson, date_format)\n",
    "\n",
    "    pellettimes = [(t - refpoint).total_seconds() / 3600 for t in timestamps]\n",
    "\n",
    "    return pellettimes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2506f741-e82c-48b2-98ed-251934a85c06",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '\\\\workspaces\\\\FEDPROFERENCE\\\\FEDXD_METAFILE.xls'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 93\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;66;03m#%%\u001b[39;00m\n\u001b[0;32m     90\u001b[0m \n\u001b[0;32m     91\u001b[0m \u001b[38;5;66;03m# function to get timestamps from fed csv files\u001b[39;00m\n\u001b[0;32m     92\u001b[0m metafile \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/workspaces/FEDPROFERENCE/FEDXD_METAFILE.xls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 93\u001b[0m rows, header \u001b[38;5;241m=\u001b[39m tp\u001b[38;5;241m.\u001b[39mmetafilereader(metafile, sheetname\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMETAFILE\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     95\u001b[0m mice \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m rows:\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\DATA\\Lib\\site-packages\\trompy\\metafile_utils.py:50\u001b[0m, in \u001b[0;36mmetafilereader\u001b[1;34m(filename, sheetname, delimiter)\u001b[0m\n\u001b[0;32m     47\u001b[0m     wb\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m extension \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.xls\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 50\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m xlrd\u001b[38;5;241m.\u001b[39mopen_workbook(filename) \u001b[38;5;28;01mas\u001b[39;00m wb:\n\u001b[0;32m     51\u001b[0m         sh \u001b[38;5;241m=\u001b[39m wb\u001b[38;5;241m.\u001b[39msheet_by_name(sheetname)  \u001b[38;5;66;03m# or wb.sheet_by_name('name_of_the_sheet_here')\u001b[39;00m\n\u001b[0;32m     53\u001b[0m         header \u001b[38;5;241m=\u001b[39m sh\u001b[38;5;241m.\u001b[39mrow_values(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\DATA\\Lib\\site-packages\\xlrd\\__init__.py:166\u001b[0m, in \u001b[0;36mopen_workbook\u001b[1;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows, ignore_workbook_corruption)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen_workbook\u001b[39m(filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     85\u001b[0m                   logfile\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mstdout,\n\u001b[0;32m     86\u001b[0m                   verbosity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     93\u001b[0m                   ignore_workbook_corruption\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     94\u001b[0m                   ):\n\u001b[0;32m     95\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;124;03m    Open a spreadsheet file for data extraction.\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;124;03m    :returns: An instance of the :class:`~xlrd.book.Book` class.\u001b[39;00m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 166\u001b[0m     file_format \u001b[38;5;241m=\u001b[39m inspect_format(filename, file_contents)\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;66;03m# We have to let unknown file formats pass through here, as some ancient\u001b[39;00m\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;66;03m# files that xlrd can parse don't start with the expected signature.\u001b[39;00m\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m file_format \u001b[38;5;129;01mand\u001b[39;00m file_format \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\DATA\\Lib\\site-packages\\xlrd\\__init__.py:60\u001b[0m, in \u001b[0;36minspect_format\u001b[1;34m(path, content)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     59\u001b[0m     path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexpanduser(path)\n\u001b[1;32m---> 60\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     61\u001b[0m         peek \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread(PEEK_SIZE)\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m peek\u001b[38;5;241m.\u001b[39mstartswith(XLS_SIGNATURE):\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '\\\\workspaces\\\\FEDPROFERENCE\\\\FEDXD_METAFILE.xls'"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "# This is where I might put helper functions and scripts\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import trompy as tp\n",
    "\n",
    "def get_FEDevents(filename, eventname):\n",
    "    formats = ['%m/%d/%Y %H:%M:%S']  # Adjusted to the format in your CSV\n",
    "    file = open(filename)\n",
    "    csvreader = csv.reader(file)\n",
    "    next(csvreader)  # Skip header\n",
    "    rows = [row for row in csvreader]\n",
    "\n",
    "    if not rows:  # Check if rows is empty\n",
    "        print(f\"No data in file {filename}.\")\n",
    "        return []\n",
    "\n",
    "    # Assuming the first column contains the date and time info\n",
    "    # and the \"Event\" column is consistent with the provided files\n",
    "    event_column_index = 9  # Based on your CSV structure\n",
    "    \n",
    "    # Determine which date format should be used (assuming consistency, so just using one format)\n",
    "    date_format = formats[0]\n",
    "\n",
    "    timestamps = []\n",
    "    for row in rows:\n",
    "        if row[event_column_index] == eventname:\n",
    "            date_time_obj = datetime.strptime(row[0], date_format)\n",
    "            timestamps.append(date_time_obj)\n",
    "\n",
    "    if not timestamps:  # If no events match, return an empty list\n",
    "        return []\n",
    "\n",
    "    # Calculate time since \"lights on\", using the first event as reference if needed\n",
    "    t0 = timestamps[0].strftime(date_format)\n",
    "    day = t0.split()[0]\n",
    "    lightson = day + \" 07:00:00\"  # Assuming lights on at 7 AM\n",
    "    refpoint = datetime.strptime(lightson, date_format)\n",
    "\n",
    "    pellettimes = [(t - refpoint).total_seconds() / 3600 for t in timestamps]\n",
    "\n",
    "    return pellettimes\n",
    "\n",
    "\n",
    "def get_data_subset(dictionary, selectors, verbose=True):\n",
    "\n",
    "    output_dictionary = dictionary.copy()\n",
    "    for key, value in selectors.items():\n",
    "        for mouse_id in dictionary.keys():\n",
    "            try:\n",
    "                if output_dictionary[mouse_id][key] != value:\n",
    "                    output_dictionary.pop(mouse_id)\n",
    "            except KeyError: pass\n",
    "\n",
    "    if verbose:\n",
    "        print(\"{} items in output dictionary\".format(len(output_dictionary.keys())))\n",
    "    \n",
    "    return output_dictionary\n",
    "\n",
    "def get_data_fields(dictionary, fields, selectors):\n",
    "\n",
    "    output_list = []\n",
    "    reduced_dictionary = get_data_subset(dictionary, selectors)\n",
    "    \n",
    "    if len(reduced_dictionary.keys()) > 0:\n",
    "\n",
    "        for field in fields:\n",
    "            output_sublist =[]\n",
    "            try:\n",
    "                for key in reduced_dictionary.keys():\n",
    "                    output_sublist.append(reduced_dictionary[key][field])\n",
    "            except KeyError:\n",
    "                print(\"{} is not a key in selected dictionary\".format(field))\n",
    "                return\n",
    "            output_list.append(output_sublist)\n",
    "    else:\n",
    "        print(\"No data in fields in selected dictionary\")\n",
    "\n",
    "    if len(output_list) == 1:\n",
    "        output_list = output_list[0]\n",
    "        \n",
    "    return output_list\n",
    "\n",
    "def get_intermealinterval (pellettimes):\n",
    "    IPIs = np.diff(pellettimes)\n",
    "    IMI= np.mean([x for x in IPIs if x > (1/60)])\n",
    "    return IMI\n",
    "#%%\n",
    "\n",
    "# function to get timestamps from fed csv files\n",
    "metafile = \"/workspaces/FEDPROFERENCE/FEDXD_METAFILE.xls\"\n",
    "rows, header = tp.metafilereader(metafile, sheetname=\"METAFILE\")\n",
    "\n",
    "mice = {}\n",
    "for row in rows:\n",
    "    mouse_id = row[0]\n",
    "    if mouse_id not in mice.keys():\n",
    "        mice[mouse_id] = {}\n",
    "        mice[mouse_id][\"SEX\"] = row[1]\n",
    "        mice[mouse_id][\"CHOICE_SESSION\"] = row[4]\n",
    "        mice[mouse_id][\"FED_PELLET\"] = row[5]\n",
    "        mice[mouse_id][\"MODE\"] = row[6]\n",
    "        mice[mouse_id][\"DIET\"] = row[7]\n",
    "\n",
    "for key in mice.keys():\n",
    "    for row in rows:\n",
    "        if row[0] == key and row[6] == \"FR\":\n",
    "            filename = \"/workspaces/FEDPROFERENCE/data/{}\".format(row[3])\n",
    "            if row[5] == \"CAS20\":\n",
    "                mice[key][\"CAS20_timestamps\"] = get_FEDevents(filename, \"Pellet\")\n",
    "            elif row[7] == \"PR\":\n",
    "                mice[key][\"pr_timestamps\"] = get_FEDevents(filename, \"Pellet\")\n",
    "            elif row[7] == \"NR\":\n",
    "                mice[key][\"nr_timestamps\"] = get_FEDevents(filename, \"Pellet\")\n",
    "            else:\n",
    "                print(row[27], \"is not a valid type of pellet for\", key)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# %%\n",
    "# to get average pellets per day\n",
    "for key in mice.keys():\n",
    "    mice[key][\"grain_avg_pellets\"] = len(mice[key][\"grain_timestamps\"]) / 3\n",
    "    mice[key][\"pr_avg_pellets\"] = len(mice[key][\"pr_timestamps\"]) / 7\n",
    "    mice[key][\"nr_avg_pellets\"] = len(mice[key][\"nr_timestamps\"]) / 7\n",
    "\n",
    "# %%\n",
    "# \n",
    "def get_pellets_per_day(timestamps, start_time=4, days=7):\n",
    "    pellets_per_day = []\n",
    "    for day in range(days):\n",
    "        pellets = [t for t in timestamps if (t>day*24) and (t<(day+1)*24)]\n",
    "        n_pellets = len(pellets)\n",
    "        pellets_per_day.append(n_pellets)\n",
    "\n",
    "    return pellets_per_day\n",
    "\n",
    "for key in mice.keys():\n",
    "    mice[key][\"grain_pellets_per_day\"] = get_pellets_per_day(mice[key][\"grain_timestamps\"], days=3)\n",
    "    mice[key][\"pr_pellets_per_day\"] = get_pellets_per_day(mice[key][\"pr_timestamps\"])\n",
    "    mice[key][\"nr_pellets_per_day\"] = get_pellets_per_day(mice[key][\"nr_timestamps\"])\n",
    "\n",
    "# %%\n",
    "# assemble pellets per day for whole timecourse\n",
    "for key in mice.keys():\n",
    "    if mice[key][\"order\"] == 2:\n",
    "        mice[key][\"all_pellets_per_day\"] = mice[key][\"grain_pellets_per_day\"] + \\\n",
    "            mice[key][\"pr_pellets_per_day\"] + mice[key][\"nr_pellets_per_day\"]\n",
    "    else:\n",
    "                mice[key][\"all_pellets_per_day\"] = mice[key][\"grain_pellets_per_day\"] + \\\n",
    "                    mice[key][\"nr_pellets_per_day\"] + mice[key][\"pr_pellets_per_day\"]\n",
    "\n",
    "\n",
    "\n",
    "# %%\n",
    "# add meal parameters to dictionary\n",
    "\n",
    "def get_interpellet_intervals(pellettimes):\n",
    "    IPIs = np.diff(pellettimes)\n",
    "    return IPIs\n",
    "\n",
    "def get_intermealinterval (pellettimes):\n",
    "    IPIs = np.diff(pellettimes)\n",
    "    IMI= np.mean([x for x in IPIs if x > (1/60)])\n",
    "    return IMI\n",
    "\n",
    "def get_mealsize(pellettimes):\n",
    "    \"\"\"\n",
    "    calculates meal size from times of pellets\n",
    "    parameters \n",
    "    ----------\n",
    "    pellettimes : list of floats\n",
    "        timestamps of pellet deliveries\n",
    "\n",
    "    returns\n",
    "    --------\n",
    "    mealsize : float \n",
    "        mean size of meal in pellets \n",
    "    \"\"\"\n",
    "    npellets = len(pellettimes)\n",
    "    IPIs = np.diff(pellettimes)\n",
    "    nmeals = len([idx for idx, val in enumerate(IPIs) if val > 1/60])\n",
    "    mealsize = npellets/nmeals\n",
    "\n",
    "    return mealsize\n",
    "\n",
    "for key in mice.keys():\n",
    "    pr_timestamps = mice[key][\"pr_timestamps\"]\n",
    "    mice[key][\"interpellet_intervals_pr\"] = get_interpellet_intervals(pr_timestamps)\n",
    "    mice[key][\"intermeal_interval_pr\"] = get_intermealinterval(pr_timestamps)\n",
    "    mice[key][\"mealsize_pr\"] = get_mealsize(pr_timestamps)\n",
    "\n",
    "    nr_timestamps = mice[key][\"nr_timestamps\"]\n",
    "    mice[key][\"interpellet_intervals_nr\"] = get_interpellet_intervals(nr_timestamps)\n",
    "    mice[key][\"intermeal_interval_nr\"] = get_intermealinterval(nr_timestamps)\n",
    "    mice[key][\"mealsize_nr\"] = get_mealsize(nr_timestamps)\n",
    "    \n",
    "# %%\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "209b516e-fdb7-4055-a0dd-5ed0e6bba330",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '\\\\workspaces\\\\FEDPROFERENCE\\\\FEDXD_METAFILE.xls'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Ensure trompy is correctly installed and imported, or use an alternative method to read the Excel file.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Read the metafile (assuming tp.metafilereader is correctly implemented)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m metafile_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/workspaces/FEDPROFERENCE/FEDXD_METAFILE.xls\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Adjusted path to the uploaded file\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m rows, header \u001b[38;5;241m=\u001b[39m tp\u001b[38;5;241m.\u001b[39mmetafilereader(metafile_path, sheetname\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMETAFILE\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m mice \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Iterate through each row in the metafile to populate the mice dictionary\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\DATA\\Lib\\site-packages\\trompy\\metafile_utils.py:50\u001b[0m, in \u001b[0;36mmetafilereader\u001b[1;34m(filename, sheetname, delimiter)\u001b[0m\n\u001b[0;32m     47\u001b[0m     wb\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m extension \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.xls\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 50\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m xlrd\u001b[38;5;241m.\u001b[39mopen_workbook(filename) \u001b[38;5;28;01mas\u001b[39;00m wb:\n\u001b[0;32m     51\u001b[0m         sh \u001b[38;5;241m=\u001b[39m wb\u001b[38;5;241m.\u001b[39msheet_by_name(sheetname)  \u001b[38;5;66;03m# or wb.sheet_by_name('name_of_the_sheet_here')\u001b[39;00m\n\u001b[0;32m     53\u001b[0m         header \u001b[38;5;241m=\u001b[39m sh\u001b[38;5;241m.\u001b[39mrow_values(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\DATA\\Lib\\site-packages\\xlrd\\__init__.py:166\u001b[0m, in \u001b[0;36mopen_workbook\u001b[1;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows, ignore_workbook_corruption)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen_workbook\u001b[39m(filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     85\u001b[0m                   logfile\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mstdout,\n\u001b[0;32m     86\u001b[0m                   verbosity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     93\u001b[0m                   ignore_workbook_corruption\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     94\u001b[0m                   ):\n\u001b[0;32m     95\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;124;03m    Open a spreadsheet file for data extraction.\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;124;03m    :returns: An instance of the :class:`~xlrd.book.Book` class.\u001b[39;00m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 166\u001b[0m     file_format \u001b[38;5;241m=\u001b[39m inspect_format(filename, file_contents)\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;66;03m# We have to let unknown file formats pass through here, as some ancient\u001b[39;00m\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;66;03m# files that xlrd can parse don't start with the expected signature.\u001b[39;00m\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m file_format \u001b[38;5;129;01mand\u001b[39;00m file_format \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\DATA\\Lib\\site-packages\\xlrd\\__init__.py:60\u001b[0m, in \u001b[0;36minspect_format\u001b[1;34m(path, content)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     59\u001b[0m     path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexpanduser(path)\n\u001b[1;32m---> 60\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     61\u001b[0m         peek \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread(PEEK_SIZE)\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m peek\u001b[38;5;241m.\u001b[39mstartswith(XLS_SIGNATURE):\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '\\\\workspaces\\\\FEDPROFERENCE\\\\FEDXD_METAFILE.xls'"
     ]
    }
   ],
   "source": [
    "# Ensure trompy is correctly installed and imported, or use an alternative method to read the Excel file.\n",
    "\n",
    "# Read the metafile (assuming tp.metafilereader is correctly implemented)\n",
    "metafile_path = \"/workspaces/FEDPROFERENCE/FEDXD_METAFILE.xls\"  # Adjusted path to the uploaded file\n",
    "rows, header = tp.metafilereader(metafile_path, sheetname=\"METAFILE\")\n",
    "\n",
    "mice = {}\n",
    "# Iterate through each row in the metafile to populate the mice dictionary\n",
    "for row in rows:\n",
    "    mouse_id, choice_session = row[0], row[4]  # Assuming these are the correct indices for MOUSEID and CHOICE_SESSION\n",
    "    if mouse_id not in mice:\n",
    "        mice[mouse_id] = {\"CHOICE_SESSION\": choice_session, \"events\": []}  # Initialize dictionary\n",
    "\n",
    "# Now, focus on processing FED event data for CHOICE_SESSION\n",
    "for mouse_id, data in mice.items():\n",
    "    choice_session = data[\"CHOICE_SESSION\"]\n",
    "    # Filter rows for the current mouse and its CHOICE_SESSION\n",
    "    session_rows = [row for row in rows if row[0] == mouse_id and row[4] == choice_session]\n",
    "    \n",
    "    for row in session_rows:\n",
    "        # Assuming row[3] is the filename/path for the FED event data\n",
    "        filename = f\"/workspaces/FEDPROFERENCE/data/{row[3]}\"  # Adjust path as needed\n",
    "        eventname = \"Pellet\"  # Adjust as needed based on your CSV files\n",
    "        # Collect FED event timestamps\n",
    "        timestamps = get_FEDevents(filename, eventname)\n",
    "        # Store timestamps in the mice dictionary\n",
    "        if timestamps:  # Check if timestamps were found\n",
    "            mice[mouse_id][\"events\"].extend(timestamps)\n",
    "\n",
    "# This approach organizes the FED event timestamps by mouse and by CHOICE_SESSION.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "050e45e7-2b91-4e1d-a5e5-ffed6ef0e575",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mice' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Assuming the metafile processing part remains the same\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Extending the mice dictionary to include pellet types\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mouse_id, data \u001b[38;5;129;01min\u001b[39;00m mice\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m      5\u001b[0m     choice_session \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCHOICE_SESSION\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      6\u001b[0m     session_rows \u001b[38;5;241m=\u001b[39m [row \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m rows \u001b[38;5;28;01mif\u001b[39;00m row[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m mouse_id \u001b[38;5;129;01mand\u001b[39;00m row[\u001b[38;5;241m4\u001b[39m] \u001b[38;5;241m==\u001b[39m choice_session]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mice' is not defined"
     ]
    }
   ],
   "source": [
    "# Assuming the metafile processing part remains the same\n",
    "\n",
    "# Extending the mice dictionary to include pellet types\n",
    "for mouse_id, data in mice.items():\n",
    "    choice_session = data[\"CHOICE_SESSION\"]\n",
    "    session_rows = [row for row in rows if row[0] == mouse_id and row[4] == choice_session]\n",
    "\n",
    "    # Initialize dictionary entries for pellet counts\n",
    "    data[\"pellet_counts\"] = {}  # This will store counts for each pellet type\n",
    "\n",
    "    for row in session_rows:\n",
    "        filename = f\"/workspaces/FEDPROFERENCE/data/{row[3]}\"  # Adjust path as needed\n",
    "        # Assuming pellet types are differentiated somehow in your data or filenames\n",
    "        # For illustration, let's say pellet types are indicated in `FED_PELLET` column (row[5])\n",
    "        pellet_type = row[5]  # Identify the pellet type\n",
    "        if pellet_type not in data[\"pellet_counts\"]:\n",
    "            data[\"pellet_counts\"][pellet_type] = 0  # Initialize count for this pellet type\n",
    "        \n",
    "        # Here you might need to adjust the event name to match the specific pellet type\n",
    "        # This is an example assuming all pellets are logged as \"Pellet\" events\n",
    "        # You might need to adjust this logic based on how your data indicates pellet type\n",
    "        timestamps = get_FEDevents(filename, \"Pellet\")  # Collect timestamps\n",
    "        data[\"pellet_counts\"][pellet_type] += len(timestamps)  # Count pellets for the type\n",
    "\n",
    "# Now, `mice[mouse_id][\"pellet_counts\"]` contains the counts of each pellet type taken in the choice session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6af5cd3-f3c9-4fc0-97f8-c5bf07d1ba49",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mice' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m grouped_data \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Iterate through each mouse to organize their data into the corresponding list\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mouse_id, data \u001b[38;5;129;01min\u001b[39;00m mice\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# Using .get() to avoid KeyError, defaulting to 'Unknown' if not found\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     sex \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSEX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Consider how you want to handle unknown sexes\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     choice_session \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCHOICE_SESSION\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mice' is not defined"
     ]
    }
   ],
   "source": [
    "# Initialize a dictionary to hold the lists for each group\n",
    "grouped_data = {}\n",
    "\n",
    "# Iterate through each mouse to organize their data into the corresponding list\n",
    "for mouse_id, data in mice.items():\n",
    "    # Using .get() to avoid KeyError, defaulting to 'Unknown' if not found\n",
    "    sex = data.get(\"SEX\", \"Unknown\")  # Consider how you want to handle unknown sexes\n",
    "    choice_session = data.get(\"CHOICE_SESSION\", \"Unknown\")\n",
    "    diet = data.get(\"DIET\", \"Unknown\")\n",
    "    \n",
    "    # Check if 'pellet_counts' exists to avoid further errors\n",
    "    pellet_counts = data.get(\"pellet_counts\", {})\n",
    "    \n",
    "    # Iterate through pellet counts to further classify by pellet type\n",
    "    for pellet_type, count in pellet_counts.items():\n",
    "        # Define a unique key for the group\n",
    "        key = f\"{sex}_{choice_session}_{diet}_{pellet_type}\"\n",
    "        \n",
    "        # Initialize the list for this group if it doesn't exist\n",
    "        if key not in grouped_data:\n",
    "            grouped_data[key] = []\n",
    "        \n",
    "        # Append the mouse data to the list for its group\n",
    "        grouped_data[key].append({\n",
    "            \"MOUSEID\": mouse_id,\n",
    "            \"COUNT\": count\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0dc2ac5-19eb-4d7c-aff8-7248d824102e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rows' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m all_sessions_data \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Iterate through each row directly, allowing for multiple sessions per mouse\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m rows:\n\u001b[0;32m      6\u001b[0m     mouse_id \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      7\u001b[0m     choice_session \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;241m4\u001b[39m]  \u001b[38;5;66;03m# This is now directly taken from each row\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'rows' is not defined"
     ]
    }
   ],
   "source": [
    "# Initialize a structure to store data across all choice sessions\n",
    "all_sessions_data = {}\n",
    "\n",
    "# Iterate through each row directly, allowing for multiple sessions per mouse\n",
    "for row in rows:\n",
    "    mouse_id = row[0]\n",
    "    choice_session = row[4]  # This is now directly taken from each row\n",
    "    pellet_type = row[5]\n",
    "    filename = f\"/workspaces/FEDPROFERENCE/data/{row[3]}\"\n",
    "    \n",
    "    # Unique key for each mouse, session, and pellet type\n",
    "    key = f\"{mouse_id}_{choice_session}_{pellet_type}\"\n",
    "    \n",
    "    # Initialize the entry if it doesn't exist\n",
    "    if key not in all_sessions_data:\n",
    "        all_sessions_data[key] = {\n",
    "            \"MOUSEID\": mouse_id,\n",
    "            \"CHOICE_SESSION\": choice_session,\n",
    "            \"PELLET_TYPE\": pellet_type,\n",
    "            \"COUNT\": 0\n",
    "        }\n",
    "    \n",
    "    # Collect timestamps and count pellets for the type\n",
    "    timestamps = get_FEDevents(filename, \"Pellet\")\n",
    "    all_sessions_data[key][\"COUNT\"] += len(timestamps)\n",
    "\n",
    "# Convert all_sessions_data dictionary to a list of dictionaries for each mouse/session/pellet type\n",
    "all_sessions_list = list(all_sessions_data.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bec6c72c-93b6-43dd-ba0b-20566ef45275",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rows' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m grouped_lists \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Iterate through the rows to process and group data\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m rows:\n\u001b[0;32m      6\u001b[0m     mouse_id \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      7\u001b[0m     sex \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# Assuming this is the correct column for SEX\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'rows' is not defined"
     ]
    }
   ],
   "source": [
    "# Initialize a dictionary to hold lists for each unique group\n",
    "grouped_lists = {}\n",
    "\n",
    "# Iterate through the rows to process and group data\n",
    "for row in rows:\n",
    "    mouse_id = row[0]\n",
    "    sex = row[1]  # Assuming this is the correct column for SEX\n",
    "    diet = row[7]  # Assuming this is the correct column for DIET\n",
    "    choice_session = row[4]\n",
    "    pellet_type = row[5]\n",
    "    filename = f\"/workspaces/FEDPROFERENCE/data/{row[3]}\"\n",
    "    \n",
    "    # Create a unique key for each group\n",
    "    group_key = f\"{sex}_{diet}_{choice_session}_{pellet_type}\"\n",
    "    \n",
    "    # Collect timestamps for this row's file and pellet event\n",
    "    timestamps = get_FEDevents(filename, \"Pellet\")\n",
    "    pellet_count = len(timestamps)\n",
    "    \n",
    "    # Initialize the list for this group if it doesn't exist\n",
    "    if group_key not in grouped_lists:\n",
    "        grouped_lists[group_key] = []\n",
    "    \n",
    "    # Append the data for this mouse to the list for its group\n",
    "    grouped_lists[group_key].append({\n",
    "        \"MOUSEID\": mouse_id,\n",
    "        \"SEX\": sex,\n",
    "        \"DIET\": diet,\n",
    "        \"CHOICE_SESSION\": choice_session,\n",
    "        \"PELLET_TYPE\": pellet_type,\n",
    "        \"COUNT\": pellet_count\n",
    "    })\n",
    "\n",
    "# At this point, 'grouped_lists' contains separate lists for each combination of SEX, DIET, CHOICE_SESSION, and PELLET_TYPE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d514a4d2-4900-4c61-8f14-f3b4ef3314c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'grouped_lists' is your dictionary containing the grouped data\n",
    "\n",
    "# Flatten the grouped data into a single list of dictionaries\n",
    "flattened_data = []\n",
    "for group_data in grouped_lists.values():\n",
    "    flattened_data.extend(group_data)\n",
    "\n",
    "# Convert the flattened data list into a DataFrame\n",
    "df = pd.DataFrame(flattened_data)\n",
    "\n",
    "# Display the first few rows of the DataFrame to verify\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a4ac875-76f3-4fdf-ae0d-81e0b72f844b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filename' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Assuming you're within the loop where you collect FED event timestamps for each session\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# For each mouse session, after collecting timestamps\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m timestamps \u001b[38;5;241m=\u001b[39m get_FEDevents(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPellet\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# This gets the timestamps for the session\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Convert timestamps to hours since the first event (if not already in this format)\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Assumes timestamps are sorted in ascending order\u001b[39;00m\n\u001b[0;32m     10\u001b[0m pellettimes \u001b[38;5;241m=\u001b[39m [((t \u001b[38;5;241m-\u001b[39m timestamps[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mtotal_seconds() \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m3600\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m timestamps]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'filename' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming you're within the loop where you collect FED event timestamps for each session\n",
    "\n",
    "# For each mouse session, after collecting timestamps\n",
    "timestamps = get_FEDevents(filename, \"Pellet\")  # This gets the timestamps for the session\n",
    "\n",
    "# Convert timestamps to hours since the first event (if not already in this format)\n",
    "# Assumes timestamps are sorted in ascending order\n",
    "pellettimes = [((t - timestamps[0]).total_seconds() / 3600) for t in timestamps]\n",
    "\n",
    "# Calculate Interpellet Intervals (IPIs), Intermeal Interval (IMI), and Meal Size\n",
    "IPIs = get_interpellet_intervals(pellettimes)\n",
    "IMI = get_intermealinterval(pellettimes)\n",
    "mealsize = get_mealsize(pellettimes)\n",
    "\n",
    "# Now, you can include IMI and Meal Size in your data structure for this session\n",
    "grouped_lists[group_key].append({\n",
    "    \"MOUSEID\": mouse_id,\n",
    "    \"SEX\": sex,\n",
    "    \"DIET\": diet,\n",
    "    \"CHOICE_SESSION\": choice_session,\n",
    "    \"PELLET_TYPE\": pellet_type,\n",
    "    \"COUNT\": pellet_count,\n",
    "    \"IMI\": IMI,\n",
    "    \"MEALSIZE\": mealsize\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f03e732-7ad9-4543-b9d1-0a8427d11fe2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
